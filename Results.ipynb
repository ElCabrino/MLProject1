{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run algebra.py\n",
    "%run cache.py\n",
    "%run costs.py\n",
    "%run features.py\n",
    "%run gradients.py\n",
    "%run helpers.py\n",
    "%run model.py\n",
    "%run splits.py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_SAMPLE = False\n",
    "CACHE_DIR = \"test/cache/\" if SUB_SAMPLE else \"cache/\"\n",
    "SUBMISSIONS_DIR = \"test/submissions/\" if SUB_SAMPLE else \"submissions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x, ids = load_csv_data('data/train.csv', SUB_SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Analytical Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression with Fixed Degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Without Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression_MSE_FixedDegree_Model(Model):\n",
    "\n",
    "    def prepare(self, x, y, h):\n",
    "        \n",
    "        degree = int(h['degree'])\n",
    "\n",
    "        x = remove_errors(x)\n",
    "        x = remove_outliers(x)\n",
    "        x = standardize_all(x)\n",
    "        x = remove_nan_features(x)\n",
    "        x = build_poly(x, degree)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def fit(self, x, y, h):\n",
    "\n",
    "        lambda_ = float(h['lambda'])\n",
    "        degree = int(h['degree'])\n",
    "\n",
    "        return ridge_regression(y, x, lambda_)     \n",
    "        \n",
    "    def test(self, x, y, w, h):\n",
    "                \n",
    "        return { 'mse': compute_mse(y, x, w) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = RidgeRegression_MSE_FixedDegree_Model()\n",
    "\n",
    "hs = { \n",
    "    'degree': np.arange(4, 16), \n",
    "    'lambda': np.logspace(-8, -2, 7),\n",
    "}\n",
    "\n",
    "res = myModel.evaluate(x, y, hs,filename=CACHE_DIR+'RidgeRegression_MSE_FixedDegree')\n",
    "res_mse = np.vectorize(lambda x: x['mse'])(res)\n",
    "\n",
    "plot_heatmap(res, hs, 'mse', 'degree', 'lambda')\n",
    "find_arg_min(res, 'mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Cross-Validation\n",
    "\n",
    "Here, we implement the same model with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = CrossValidationModel(RidgeRegression_MSE_FixedDegree_Model())\n",
    "\n",
    "hs = { \n",
    "    'degree': np.arange(4, 16), \n",
    "    'lambda': np.logspace(-8, -2, 7),\n",
    "    'k_fold': 4,\n",
    "    'seed': 0\n",
    "}\n",
    "\n",
    "res = myModel.evaluate(x, y, hs, CACHE_DIR+'RidgeRegression_MSE_FixedDegree_CrossValidation')\n",
    "\n",
    "plot_heatmap(res, hs, 'avg_mse_te', 'degree', 'lambda')\n",
    "best_h = find_arg_min(res, 'avg_mse_te')\n",
    "best_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel.predict(best_h, x, y, SUBMISSIONS_DIR + 'RidgeRegression_MSE_FixedDegree_CrossValidation_Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descents\n",
    "\n",
    "#### Least Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE_Gradient_FixedDegree_Model(Model):\n",
    "    \n",
    "    def prepare(self, x, y, h):\n",
    "        \n",
    "        degree = int(h['degree'])\n",
    "\n",
    "        x = remove_errors(x)\n",
    "        x = remove_outliers(x)\n",
    "        x = standardize_all(x)\n",
    "        x = remove_nan_features(x)\n",
    "        x = build_poly(x, degree)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def compute_gradient(self, y, x, w, h):\n",
    "    \n",
    "        e = y - x @ w\n",
    "        grad = -x.T.dot(e) / len(e)\n",
    "    \n",
    "        return grad\n",
    "    \n",
    "    def test(self, x, y, w, h):\n",
    "        \n",
    "        return { 'mse': compute_mse(y, x, w) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE_Gradient_RidgeRegression_FixedDegree_Model(Model):\n",
    "    \n",
    "    def prepare(self, x, y, h):\n",
    "        \n",
    "        degree = int(h['degree'])\n",
    "\n",
    "        x = remove_errors(x)\n",
    "        x = remove_outliers(x)\n",
    "        x = standardize_all(x)\n",
    "        x = remove_nan_features(x)\n",
    "        x = build_poly(x, degree)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def compute_gradient(self, y, x, w, h):\n",
    "    \n",
    "        lambda_ = float(h['lambda'])\n",
    "    \n",
    "        e = y - x @ w\n",
    "        grad = (-x.T.dot(e) + (2 * lambda_ * w)) / len(e)\n",
    "    \n",
    "        return grad\n",
    "    \n",
    "    def test(self, x, y, w, h):\n",
    "\n",
    "        return { 'mse': compute_mse(y, x, w) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE_Gradient_Lasso_FixedDegree_Model(Model):\n",
    "    \n",
    "    def prepare(self, x, y, h):\n",
    "        \n",
    "        degree = int(h['degree'])\n",
    "\n",
    "        x = remove_errors(x)\n",
    "        x = remove_outliers(x)\n",
    "        x = standardize_all(x)\n",
    "        x = remove_nan_features(x)\n",
    "        x = build_poly(x, degree)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def compute_gradient(self, y, x, w, h):\n",
    "    \n",
    "        lambda_ = float(h['lambda'])\n",
    "    \n",
    "        e = y - x @ w\n",
    "        \n",
    "        grad = (-x.T.dot(e) + (lambda_ * np.sign(w))) / len(e)\n",
    "    \n",
    "        return grad\n",
    "    \n",
    "    def test(self, x, y, w, h):\n",
    "\n",
    "        return { 'mse': compute_mse(y, x, w) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = CrossValidationModel(StochasticGradientDescent(MSE_Gradient_Lasso_FixedDegree_Model()))\n",
    "\n",
    "hs = { \n",
    "    'degree': np.arange(4, 8), \n",
    "    'lambda': 0.0000001,\n",
    "    'k_fold': 4,\n",
    "    'seed': 0,\n",
    "    'batch_size': 1,\n",
    "    'max_iters': np.array([1000]),\n",
    "    'num_batches': 1,\n",
    "    'gamma': np.array([0.0000001])\n",
    "}\n",
    "\n",
    "res = myModel.evaluate(x, y, hs, CACHE_DIR+'MSE_Lasso_Gradient_FixedDegree_CrossValidation')\n",
    "\n",
    "plot_heatmap(res, hs, 'avg_mse_te', 'degree', 'lambda')\n",
    "best_h = find_arg_min(res, 'avg_mse_te')\n",
    "best_h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
