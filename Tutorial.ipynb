{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from cache import *\n",
    "from costs import *\n",
    "from features import *\n",
    "from helpers import *\n",
    "from evaluate import *\n",
    "from predict import *\n",
    "from validate import *\n",
    "from implementations import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will see how to run a basic model and how to do some grid search on the model's parameter.\n",
    "\n",
    "First, we define the directories path. You can specifiy if you want to load a sub sample of the data set or the full dataset by changing the `SUB_SAMPLE` constant to `True` or `False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_SAMPLE = True\n",
    "CACHE_DIR = \"test/cache/\" if SUB_SAMPLE else \"cache/\"\n",
    "SUBMISSIONS_DIR = \"test/submissions/\" if SUB_SAMPLE else \"submissions/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we load our data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x, ids = load_csv_data('data/train.csv', SUB_SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define how we want to process our dataset before doing any training. For this dataset we do the following preprocessing steps:\n",
    "1. we remove all the `-999` values\n",
    "2. we remove the outliers with a clamping\n",
    "3. we standardize our dataset\n",
    "4. we do a polynomial expansion with the `degree` value passed as hyperparameter\n",
    "\n",
    "The functions used in this function are in the file `features.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_standardize_expand(y, x, h):\n",
    "        \n",
    "    degree = int(h['degree'])\n",
    "\n",
    "    x = remove_errors(x)\n",
    "    x = remove_outliers(x)\n",
    "    x = standardize_all(x)\n",
    "    x = remove_nan_features(x)\n",
    "    x = build_poly(x, degree)\n",
    "\n",
    "    return y, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters exploration for a simple Least Squares model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to try some models with different parameters to see which one is the best for our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the parameters we want to explore. Since least squares is a simple model we only have the degree expansion to explore, let's see the results with the degree varying from 10 to 13:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#where we store our results\n",
    "cache = Cache(CACHE_DIR + 'Tutorial_Least_Squares')\n",
    "\n",
    "#the parameters we want to try\n",
    "hs = { \n",
    "    'degree': np.arange(10, 14), \n",
    "}\n",
    "\n",
    "#compute the values for each model\n",
    "evaluate(\n",
    "    fit   = clean_and_fit_with_cache(\n",
    "        clean = clean_standardize_expand,\n",
    "        fit = least_squares_weights, \n",
    "        cache = cache\n",
    "    ),  \n",
    "    y     = y, \n",
    "    x     = x, \n",
    "    hs    = hs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we take a look at `test/cache/Tutorial_Results.csv` we can see that the best model is the one with the polynomial expansion of 13th degree. \n",
    "\n",
    "This workflow is very basic and only return the weights of the differents model we trained. To have the error on a test set we can use the `cross_validation` wrapper function. We first need to define the loss function that will feedback our cross validation. \n",
    "\n",
    "Here we will use the basic `compute_mse` function. The `mse` key added is used by the cache to name correctly the column in the generated file. The columns will have the name `avg_mse_tr` and `avg_mse_te`.\n",
    "\n",
    "Note that if we change the key name to `loss` for example, in the file we would get `avg_loss_tr` and `avg_loss_te`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y, x, w, h):\n",
    "    return {\n",
    "        'mse' : compute_mse(y, x, w)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#where we store our results\n",
    "cache = Cache(CACHE_DIR + 'Tutorial_Least_Squares_Cross_Validation')\n",
    "\n",
    "#the parameters we want to try\n",
    "hs = { \n",
    "    'degree': np.arange(10, 14), \n",
    "    'k_fold': 4,\n",
    "    'seed': 1\n",
    "}\n",
    "\n",
    "res = evaluate(\n",
    "    fit   = clean_and_fit_with_cache(\n",
    "        clean = clean_standardize_expand,\n",
    "        fit = cross_validate(\n",
    "                fit = least_squares_weights,\n",
    "                validate = mse\n",
    "        ),\n",
    "        cache = cache\n",
    "    ),  \n",
    "    y     = y, \n",
    "    x     = x, \n",
    "    hs    = hs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The big advantage of our cross validation implementation is that we can easily find the best parameters with the function `find_arg_min` based on a specific criteria. \n",
    "\n",
    "Here we want to have the model that have the smallest `avg_mse_te` since the test erros are more representative of the actual quality of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_arg_min(res, 'avg_mse_te')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that the best `avg_mse_te` we have is with the model with the polynomial expansion of 10th degree.\n",
    "\n",
    "Let's verify our results on the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_SAMPLE = False\n",
    "CACHE_DIR = \"test/cache/\" if SUB_SAMPLE else \"cache/\"\n",
    "SUBMISSIONS_DIR = \"test/submissions/\" if SUB_SAMPLE else \"submissions/\"\n",
    "\n",
    "y, x, ids = load_csv_data('data/train.csv', SUB_SAMPLE)\n",
    "\n",
    "#Now we will store on cache/\n",
    "cache = Cache(CACHE_DIR + 'Tutorial_Least_Squares_Cross_Validation')\n",
    "\n",
    "res = evaluate(\n",
    "    fit   = clean_and_fit_with_cache(\n",
    "        clean = clean_standardize_expand,\n",
    "        fit = cross_validate(\n",
    "                fit = least_squares_weights,\n",
    "                validate = mse\n",
    "        ),\n",
    "        cache = cache\n",
    "    ),  \n",
    "    y     = y, \n",
    "    x     = x, \n",
    "    hs    = hs\n",
    ")\n",
    "\n",
    "find_arg_min(res, 'avg_mse_te')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now we want to submit our best model. We do the following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = { \n",
    "    'degree': 13, \n",
    "    'k_fold': 4,\n",
    "    'seed': 1\n",
    "}\n",
    "\n",
    "res = evaluate(\n",
    "    clean_and_fit_with_cache(\n",
    "        clean = clean_standardize_expand, \n",
    "        fit = cross_validate(least_squares_weights, mse),\n",
    "        cache = cache\n",
    "    ),\n",
    "    y     = y, \n",
    "    x     = x, \n",
    "    hs    = hs\n",
    ")\n",
    "\n",
    "best_w = res[0]['w']\n",
    "\n",
    "print(best_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fetched the weight of our best model from the cache, now we can do our predictions on the true test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, x_test, ids_test = load_csv_data('data/test.csv', SUB_SAMPLE)\n",
    "\n",
    "#we need to preprocess the test set too\n",
    "y_test, x_test = clean_standardize_expand(y_test, x_test, hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_values(x_test, best_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now make our submission file in the `submission/` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(ids_test, y_pred, SUBMISSIONS_DIR + 'Tutorial_Least_Squares_Cross_Validation_Degree_13')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters exploration for a Stochastic Gradient Descent with Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_SAMPLE = True\n",
    "CACHE_DIR = \"test/cache/\" if SUB_SAMPLE else \"cache/\"\n",
    "SUBMISSIONS_DIR = \"test/submissions/\" if SUB_SAMPLE else \"submissions/\"\n",
    "\n",
    "y, x, ids = load_csv_data('data/train.csv', SUB_SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the parameters of a simple GD models with the Least Squares gradient. We do the same cleaning as before.\n",
    "\n",
    "First we try without cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = Cache(CACHE_DIR + 'Tutorial_Gradient_Descent_Least_Squares')\n",
    "\n",
    "hs = {\n",
    "    'degree': np.arange(1,5),\n",
    "    'gamma': np.logspace(-10, -5, 5),\n",
    "    'max_iters': 100,\n",
    "    'seed': 1\n",
    "}\n",
    "\n",
    "evaluate(\n",
    "    fit   = clean_and_descent_with_cache(\n",
    "        clean = clean_standardize_expand,\n",
    "        descent = descent_with_loss(\n",
    "                    descent = gradient_descent(least_squares_gradient),\n",
    "                    loss = mse\n",
    "        ),\n",
    "        round_size = 50,\n",
    "        cache = cache,\n",
    "        multiple = False\n",
    "    ),  \n",
    "    y     = y, \n",
    "    x     = x, \n",
    "    hs    = hs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we wrapped `gradient_descent` with the function `descent_with_loss` in order to print the loss in the log. Any loss function can be used.\n",
    "\n",
    "We can also use a cross validation for the descent model by wrapping our descent model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = Cache(CACHE_DIR + 'Tutorial_Gradient_Descent_Least_Squares_Cross_Validation')\n",
    "\n",
    "hs = {\n",
    "    'degree': np.arange(1,5),\n",
    "    'gamma': np.logspace(-10, -5, 5),\n",
    "    'max_iters': 100,\n",
    "    'k_fold': 4,\n",
    "    'seed_cv': 1,\n",
    "    'seed': 1\n",
    "}\n",
    "\n",
    "res = evaluate(\n",
    "    fit   = clean_and_descent_with_cache(\n",
    "        clean = clean_standardize_expand,\n",
    "        descent = cross_validate_descent(\n",
    "                    descent = descent_with_loss(\n",
    "                        descent = gradient_descent(least_squares_gradient),\n",
    "                        loss = mse\n",
    "                    ),\n",
    "                    validate = mse\n",
    "        ),                               \n",
    "        round_size = 50,\n",
    "        cache = cache,\n",
    "        log = False\n",
    "    ),  \n",
    "    y     = y, \n",
    "    x     = x, \n",
    "    hs    = hs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we find the best parameters for this gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_arg_min(res, 'avg_mse_te')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots for parameters exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a useful fonction `plot_heatmap` that takes the result of the evaluate function, the name of the loss we want to plot, and the x-y axis.\n",
    "\n",
    "Here we want to visualize the `avg_mse_te` we have as a parameter of `degree` and `gamma`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(res, 'avg_mse_te', 'degree', 'gamma')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
