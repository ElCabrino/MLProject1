{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from cache import *\n",
    "from costs import *\n",
    "from features import *\n",
    "from gradients import *\n",
    "from helpers import *\n",
    "from evaluate import *\n",
    "from predict import *\n",
    "from validate import *\n",
    "from implementations import *\n",
    "# from\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_SAMPLE = True\n",
    "CACHE_DIR = \"test/cache/\" if SUB_SAMPLE else \"cache/\"\n",
    "SUBMISSIONS_DIR = \"test/submissions/\" if SUB_SAMPLE else \"submissions/\"\n",
    "\n",
    "y, x, ids = load_csv_data('data/train.csv', SUB_SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Analytical Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression with Fixed Degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Without Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_standardize_expand(y, x, h):\n",
    "        \n",
    "    degree = int(h['degree'])\n",
    "\n",
    "    x = remove_errors(x)\n",
    "    x = remove_outliers(x)\n",
    "    x = standardize_all(x)\n",
    "    x = remove_nan_features(x)\n",
    "    x = build_poly(x, degree)\n",
    "\n",
    "    return y, x\n",
    "\n",
    "def ridge_regression_analytical(y, x, h):\n",
    "\n",
    "    lambda_ = float(h['lambda'])\n",
    "    degree = int(h['degree'])\n",
    "\n",
    "    w = ridge_regression(y, x, lambda_)\n",
    "    \n",
    "    return {\n",
    "        'w': w,\n",
    "        'mse': compute_mse(y, x, w)\n",
    "    }\n",
    "\n",
    "def ridge_mse(y, x, w, h):\n",
    "\n",
    "    lambda_ = float(h['lambda'])\n",
    "    \n",
    "    mse = compute_mse(y, x, w)\n",
    "    ridge_norm = np.linalg.norm(w, 2) * lambda_\n",
    "        \n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'ridge_norm': ridge_norm,\n",
    "        'total_loss': mse + ridge_norm,\n",
    "        'n_err': compute_error_count(predict_values)(y, x, w)\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = { \n",
    "    'degree': [5, 6, 7], \n",
    "    'lambda': 1e-4,\n",
    "}\n",
    "\n",
    "_ = evaluate(\n",
    "    clean = clean_standardize_expand, \n",
    "    fit   = ridge_regression_analytical, \n",
    "    x     = x, \n",
    "    y     = y, \n",
    "    hs    = hs, \n",
    "    cache = CACHE_DIR + 'clean_standardize_expand_ridge_regression_analytical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Cross-Validation\n",
    "\n",
    "Here, we implement the same model with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = { \n",
    "    'degree': np.arange(4, 16), \n",
    "    'lambda': np.logspace(-8, -4, 5),\n",
    "    'k_fold': 4,\n",
    "    'seed': 0\n",
    "}\n",
    "\n",
    "def mse(y, x, w):\n",
    "    return { 'mse' : compute_mse(y, x, w) }\n",
    "\n",
    "\n",
    "\n",
    "evaluate(\n",
    "    clean = cross_validate(ridge_regression_analytical, mse), \n",
    "    fit   = fit_function, \n",
    "    x     = x,\n",
    "    y     = y, \n",
    "    hs    = hs, \n",
    "    cache = CACHE_DIR + 'clean_standardize_expand_cross_validate_ridge_regression_analytical_mse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myModel.predict(best_h, x, y, SUBMISSIONS_DIR + 'RidgeRegression_MSE_FixedDegree_CrossValidation_Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descents\n",
    "\n",
    "#### Least Square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_logistic(clean):\n",
    "    \n",
    "    def inner_function(y, x, h):\n",
    "        y, x = clean(y, x, h)\n",
    "        y = np.where(y == 1, 1, 0)\n",
    "        return y, x\n",
    "    \n",
    "    return inner_function\n",
    "\n",
    "def logistic_gradient(y, x, w, h):\n",
    "    \n",
    "    return compute_logistic_gradient(y, x, w)\n",
    "            \n",
    "\n",
    "\n",
    "def logistic_gradient_ridge(y, x, w, h):\n",
    "    \n",
    "    lambda_ = h['lambda']\n",
    "    \n",
    "    return compute_logistic_gradient(y, x, w) + lambda_ * w\n",
    "\n",
    "\n",
    "\n",
    "def logistic_gradient_lasso(y, x, w, h):\n",
    "    \n",
    "    lambda_ = h['lambda']\n",
    "    \n",
    "    return compute_logistic_gradient(y, x, w) + lambda_ * np.sign(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = {\n",
    "    'batch_size': 2500,\n",
    "    'degree': np.concatenate([[-2], np.arange(1, 7)]),\n",
    "    'gamma': [1e-2, 1e-3], \n",
    "    'k_fold': 4,\n",
    "    'lambda': 0,\n",
    "    'max_iters': 3000,\n",
    "    'num_batches': 1,\n",
    "    'seed': 1,\n",
    "}\n",
    "\n",
    "cache = Cache(CACHE_DIR + 'clean_standardize_expand_stochastic_logistic_descent')\n",
    "\n",
    "_ = evaluate(\n",
    "    clean = map_logistic(clean_standardize_expand), \n",
    "    fit   = descent_with_cache(\n",
    "        descent    = descent_with_loss(stochastic_gradient_descent_e(logistic_gradient), logistic_error),  \n",
    "        round_size = 100,\n",
    "        cache      = cache,\n",
    "        multiple   = False,\n",
    "        log        = True\n",
    "    ), \n",
    "    y     = y,\n",
    "    x     = x,\n",
    "    hs    = hs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Stochastic Gradient Descent With Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = {\n",
    "    'batch_size': 2500,\n",
    "    'degree': [-2] + np.arange(3, 4),\n",
    "    'gamma': [1e-2, 1e-3], \n",
    "    'lambda': [1e-2, 1e-3],\n",
    "    'k_fold': 4,\n",
    "    'max_iters': 1000,\n",
    "    'num_batches': 1,\n",
    "    'seed': 1,\n",
    "}\n",
    "\n",
    "cache = Cache(CACHE_DIR + 'clean_standardize_expand_stochastic_logistic_ridge_descent')\n",
    "\n",
    "_ = evaluate(\n",
    "    clean = map_logistic(clean_standardize_expand), \n",
    "    fit   = descent_with_cache(\n",
    "        descent    = stochastic_gradient_descent_e(logistic_gradient_ridge), \n",
    "        loss       = logistic_error_and_ridge, \n",
    "        round_size = 100,\n",
    "        cache      = cache,\n",
    "        log        = True\n",
    "    ), \n",
    "    y     = y,\n",
    "    x     = x,\n",
    "    hs    = hs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stochastic Gradient Descent With Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = {\n",
    "    'batch_size': 2500,\n",
    "    'degree': [-2, 1, 2, 3, 4, 5, 6],\n",
    "    'gamma': [1e-1, 1e-2, 1e-3], \n",
    "    'lambda': [1e-1, 1e-2, 1e-3],\n",
    "    'k_fold': 4,\n",
    "    'max_iters': 2000,\n",
    "    'num_batches': 1,\n",
    "    'seed': 0,\n",
    "}\n",
    "\n",
    "cache = Cache(CACHE_DIR + 'clean_standardize_expand_stochastic_logistic_lasso_descent')\n",
    "\n",
    "_ = evaluate(\n",
    "    clean = map_logistic(clean_standardize_expand), \n",
    "    fit   = descent_with_cache(\n",
    "        descent    = stochastic_gradient_descent_e(logistic_gradient_lasso), \n",
    "        loss       = logistic_error_and_lasso, \n",
    "        round_size = 100,\n",
    "        cache      = cache,\n",
    "        log        = True\n",
    "    ), \n",
    "    y     = y,\n",
    "    x     = x,\n",
    "    hs    = hs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = {\n",
    "    'batch_size': 2500,\n",
    "    'degree': np.concatenate([[-2], np.arange(1, 7)]),\n",
    "    'gamma': [1e-2, 1e-3], \n",
    "    'k_fold': 4,\n",
    "    'lambda': 0,\n",
    "    'max_iters': 3000,\n",
    "    'num_batches': 1,\n",
    "    'seed': 0,\n",
    "    'seed_cv': 0\n",
    "}\n",
    "\n",
    "cache = Cache(CACHE_DIR + 'clean_standardize_expand_stochastic_logistic_descent_cross_validate')\n",
    "\n",
    "_ = evaluate(\n",
    "    clean = map_logistic(clean_standardize_expand), \n",
    "    fit   = descent_with_cache(\n",
    "        descent    = cross_validate_descent(\n",
    "            stochastic_gradient_descent_e(logistic_gradient), \n",
    "            logistic_error\n",
    "        ),\n",
    "        round_size = 100,\n",
    "        cache      = cache,\n",
    "        multiple   = True,\n",
    "        log        = True\n",
    "    ), \n",
    "    y     = y,\n",
    "    x     = x,\n",
    "    hs    = hs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Descent with Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = {\n",
    "    'batch_size': 2500,\n",
    "    'degree': [-2] + np.arange(3, 4),\n",
    "    'gamma': [1e-2, 1e-3], \n",
    "    'lambda': [1e-2, 1e-3],\n",
    "    'k_fold': 4,\n",
    "    'max_iters': 1000,\n",
    "    'num_batches': 1,\n",
    "    'seed': 1,\n",
    "}\n",
    "\n",
    "cache = Cache(CACHE_DIR + 'clean_standardize_expand_stochastic_logistic_ridge_descent_cross_validate')\n",
    "\n",
    "_ = evaluate(\n",
    "    clean = map_logistic(clean_standardize_expand), \n",
    "    fit   = descent_with_cache(\n",
    "        descent    = cross_validate_descent(\n",
    "            stochastic_gradient_descent_e(logistic_gradient_ridge), \n",
    "            logistic_error_and_ridge,\n",
    "        ),\n",
    "        round_size = 100,\n",
    "        cache      = cache,\n",
    "        log        = True\n",
    "    ), \n",
    "    y     = y,\n",
    "    x     = x,\n",
    "    hs    = hs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Descent with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = {\n",
    "    'batch_size': 2500,\n",
    "    'degree': [-2] + np.arange(3, 4),\n",
    "    'gamma': [1e-2, 1e-3], \n",
    "    'lambda': [1e-2, 1e-3],\n",
    "    'k_fold': 4,\n",
    "    'max_iters': 1000,\n",
    "    'num_batches': 1,\n",
    "    'seed': 1,\n",
    "}\n",
    "\n",
    "cache = Cache(CACHE_DIR + 'clean_standardize_expand_stochastic_logistic_lasso_descent_cross_validate')\n",
    "\n",
    "_ = evaluate(\n",
    "    clean = map_logistic(clean_standardize_expand), \n",
    "    fit   = descent_with_cache(\n",
    "        descent    = cross_validate_descent(\n",
    "            stochastic_gradient_descent_e(logistic_gradient_lasso), \n",
    "            logistic_error_and_lasso,\n",
    "        ),\n",
    "        round_size = 100,\n",
    "        cache      = cache,\n",
    "        log        = True\n",
    "    ), \n",
    "    y     = y,\n",
    "    x     = x,\n",
    "    hs    = hs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_split, x_split, _ = split_data(y, x, ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Square Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = { \n",
    "    'degree': np.concatenate([np.array([-2]), np.arange(4, 16)]), \n",
    "    'lambda': np.logspace(-8, -4, 5),\n",
    "    'k_fold': 4,\n",
    "    'seed': 0\n",
    "}\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    cache = Cache(CACHE_DIR + f'clean_standardize_expand_cross_validate_ridge_regression_analytical_mse_split{i}')\n",
    "\n",
    "    result = evaluate(\n",
    "        clean = clean_standardize_expand, \n",
    "        fit   = fit_with_cache(cross_validate(ridge_regression_weights, mse_and_ridge), cache), \n",
    "        x     = x_split[i],\n",
    "        y     = y_split[i], \n",
    "        hs    = hs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_split, x_split, _ = split_data(y, x, ids)\n",
    "\n",
    "# for i in range(5):\n",
    "#     y_clean, x_clean = clean_standardize_expand(y_clean, x_clean, h)\n",
    "\n",
    "h_array = [\n",
    "    { 'degree': -2, 'lambda': 1e-8, 'k_fold': 4, 'seed': 0 },\n",
    "    { 'degree': 12, 'lambda': 1e-7, 'k_fold': 4, 'seed': 0 },\n",
    "    { 'degree': 11, 'lambda': 1e-4, 'k_fold': 4, 'seed': 0 },\n",
    "    { 'degree': 11, 'lambda': 1e-8, 'k_fold': 4, 'seed': 0 },\n",
    "    { 'degree': 10, 'lambda': 1e-8, 'k_fold': 4, 'seed': 0 }\n",
    "]\n",
    "\n",
    "caches = [Cache(CACHE_DIR + f'clean_standardize_expand_cross_validate_ridge_regression_analytical_mse_split{i}') for i in range(5)]\n",
    "\n",
    "\n",
    "res = [\n",
    "    evaluate(\n",
    "        clean_and_fit_with_cache(\n",
    "            clean_standardize_expand, \n",
    "            cross_validate(ridge_regression_weights, mse_and_ridge),\n",
    "            caches[i]\n",
    "        ),\n",
    "        x     = x_split[i],\n",
    "        y     = y_split[i], \n",
    "        hs    = h_array[i]\n",
    "    )[0] for i in range(5)\n",
    "]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = [r['w'] for r in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, x_test, ids_test = load_csv_data('data/test.csv', SUB_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x_test_split, ids_test_split = split_data(y_test, x_test, ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_split_prep = [clean_standardize_expand(None, x_test_split[i], h_array[i])[1] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = split_predict(predict_values, x_test_split_prep, ws, ids_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(ids_test, y_pred, SUBMISSIONS_DIR + 'clean_standardize_expand_cross_validate_ridge_regression_analytical_mse_split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Logistic Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = {\n",
    "    'batch_size': 2500,\n",
    "    'degree': np.concatenate([np.array([-2]), np.arange(1, 4)]), \n",
    "    'gamma': [1e-2, 1e-3], \n",
    "    'lambda': [1e-2, 1e-3],\n",
    "    'k_fold': 4,\n",
    "    'max_iters': 1000,\n",
    "    'num_batches': 1,\n",
    "    'seed': 0,\n",
    "    'seed_cv': 0\n",
    "}\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    cache = Cache(CACHE_DIR + f'clean_standardize_expand_logistic_ridge_regression_cross_validate_split{i}')\n",
    "\n",
    "    _ = evaluate(\n",
    "        clean = map_logistic(clean_standardize_expand), \n",
    "        fit   = descent_with_cache(\n",
    "            descent    = cross_validate_descent(\n",
    "                            stochastic_gradient_descent_e(logistic_gradient_ridge), \n",
    "                            logistic_error_and_ridge,\n",
    "                        ),\n",
    "            round_size = 100,\n",
    "            cache      = cache,\n",
    "            log        = True\n",
    "        ), \n",
    "        y     = y_split[i],\n",
    "        x     = x_split[i],\n",
    "        hs    = hs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = {\n",
    "    'batch_size': 2500,\n",
    "    'degree': np.concatenate([np.array([-2]), np.arange(1, 4)]), \n",
    "    'gamma': [1e-2, 1e-3], \n",
    "    'lambda': [1e-2, 1e-3],\n",
    "    'k_fold': 4,\n",
    "    'max_iters': 1000,\n",
    "    'num_batches': 1,\n",
    "    'seed': 0,\n",
    "    'seed_cv': 0\n",
    "}\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    cache = Cache(CACHE_DIR + f'clean_standardize_expand_logistic_lasso_regression_cross_validate_split{i}')\n",
    "\n",
    "    _ = evaluate(\n",
    "        clean = map_logistic(clean_standardize_expand), \n",
    "        fit   = descent_with_cache(\n",
    "            descent    = cross_validate_descent(\n",
    "                            stochastic_gradient_descent_e(logistic_gradient_lasso), \n",
    "                            logistic_error_and_lasso,\n",
    "                        ),\n",
    "            round_size = 100,\n",
    "            cache      = cache,\n",
    "            log        = True\n",
    "        ), \n",
    "        y     = y_split[i],\n",
    "        x     = x_split[i],\n",
    "        hs    = hs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
