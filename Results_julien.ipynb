{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run algebra.py\n",
    "%run cache.py\n",
    "%run costs.py\n",
    "%run features.py\n",
    "%run gradients.py\n",
    "%run helpers.py\n",
    "%run model.py\n",
    "%run models.py\n",
    "%run splits.py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(data_path, sub_sample=True):\n",
    "    \"\"\"Loads data and returns y (class labels), tX (features) and ids (event ids)\"\"\"\n",
    "    y = np.genfromtxt(data_path, delimiter=\",\", skip_header=1, dtype=str, usecols=1)\n",
    "    x = np.genfromtxt(data_path, delimiter=\",\", skip_header=1)\n",
    "    ids = x[:, 0].astype(np.int)\n",
    "    input_data = x[:, 2:]\n",
    "\n",
    "    # convert class labels from strings to binary (-1,1)\n",
    "    yb = np.ones(len(y))\n",
    "    yb[np.where(y=='b')] = -1\n",
    "\n",
    "    # sub-sample\n",
    "    if sub_sample:\n",
    "        yb = yb[::50]\n",
    "        input_data = input_data[::50]\n",
    "        ids = ids[::50]\n",
    "\n",
    "    return yb, input_data, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_SAMPLE = True\n",
    "OUTPUT_DIR = \"results_test/\" if SUB_SAMPLE else \"results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x, ids = load_csv_data('data/train.csv', sub_sample=SUB_SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Only Using Clean Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(res, hs, value, x, y):\n",
    "    val = np.vectorize(lambda x: x[value])(res)\n",
    "    \n",
    "    index = 0\n",
    "    \n",
    "    for key in sorted(hs.keys()):\n",
    "        if key == x or key == y:\n",
    "            index = index + 1\n",
    "        else:\n",
    "            val = np.apply_along_axis(np.mean, index, val)        \n",
    "    \n",
    "    ax = plt.imshow(1 / val, cmap='hot', interpolation='none')\n",
    "    plt.show()\n",
    "\n",
    "def find_arg_min(res, value):\n",
    "    val = np.vectorize(lambda x: x[value])(res)\n",
    "    index = np.where(val == val.min())\n",
    "\n",
    "    print(res[tuple([i[0] for i in index])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression with Fixed Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression_MSE_Degree_Model(Model):\n",
    "\n",
    "    def prepare(self, x, y):\n",
    "\n",
    "        return clean_data(self.raw_x), y\n",
    "\n",
    "    def fit(self, x, y, h={}):\n",
    "\n",
    "        degree = int(h['degree'])\n",
    "        lambda_ = float(h['lambda'])\n",
    "\n",
    "        tx = build_poly(x, degree)\n",
    "\n",
    "        w = ridge_regression(y, tx, lambda_)\n",
    "        mse = compute_mse(y, tx, w)\n",
    "\n",
    "        return {\n",
    "            \"mse\": mse\n",
    "        }, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = RidgeRegression_MSE_Degree_Model(x, y)\n",
    "\n",
    "hs = { \n",
    "    'degree': np.arange(20), \n",
    "    'lambda': np.logspace(-9, -3, 20)\n",
    "}\n",
    "\n",
    "res = myModel.evaluate(hs, filename=OUTPUT_DIR+'RidgeRegression_MSE_Degree_Model')\n",
    "res_mse = np.vectorize(lambda x: x['mse'])(res)\n",
    "\n",
    "plot_heatmap(res, hs, 'mse', 'degree', 'lambda')\n",
    "find_arg_min(res, 'mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression with Fixed Degree & Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression_MSE_FixedDegree_CrossValidation_Model(Model):\n",
    "\n",
    "    def prepare(self, x, y):\n",
    "\n",
    "        return clean_data(self.raw_x), y\n",
    "\n",
    "    def fit(self, x, y, h={}):\n",
    "        \n",
    "        degree = int(h['degree'])\n",
    "        lambda_ = float(h['lambda'])\n",
    "        k_fold = int(h['k_fold'])\n",
    "        seed = int(h['seed'])\n",
    "\n",
    "        avg_mse_tr = 0\n",
    "        avg_mse_te = 0\n",
    "\n",
    "        # split data in k fold\n",
    "        k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "        for k in range(0, k_fold):\n",
    "            \n",
    "            # get split data\n",
    "            x_tr, x_te, y_tr, y_te = cross_data(y, x, k_indices, k)\n",
    "\n",
    "            # form data with polynomial degree:\n",
    "            x_tr = build_poly(x_tr, degree)\n",
    "            x_te = build_poly(x_te, degree)\n",
    "\n",
    "            # ridge regression:\n",
    "            w = ridge_regression(y_tr, x_tr, lambda_)\n",
    "\n",
    "            # calculate the loss for train and test data + add it:\n",
    "            avg_mse_tr += compute_mse(y_tr, x_tr, w) / k_fold\n",
    "            avg_mse_te += compute_mse(y_te, x_te, w) / k_fold\n",
    "\n",
    "        return {\n",
    "            'avg_mse_tr': avg_mse_tr,\n",
    "            'avg_mse_te': avg_mse_te\n",
    "        }, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "myModel = RidgeRegression_MSE_FixedDegree_CrossValidation_Model(x, y)\n",
    "\n",
    "\n",
    "\n",
    "hs={ \n",
    "    'degree': np.arange(20), \n",
    "    'lambda': np.logspace(-9, -3, 20),\n",
    "    'k_fold': 5,\n",
    "    'seed': 0\n",
    "}\n",
    "\n",
    "res = myModel.evaluate(hs=hs, filename=OUTPUT_DIR+'RidgeRegression_MSE_FixedDegree_CrossValidation_Model')\n",
    "\n",
    "plot_heatmap(res, hs, 'avg_mse_te', 'degree', 'lambda')\n",
    "find_arg_min(res, 'avg_mse_te')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD_Lasso_MSE_FixedDegree_CrossValidation_Model(Model):\n",
    "\n",
    "    def prepare(self, x, y):\n",
    "\n",
    "        return clean_data(self.raw_x), y\n",
    "\n",
    "    def fit(self, x, y, h={}):\n",
    "        \n",
    "        degree = int(h['degree'])\n",
    "        lambda_ = float(h['lambda'])\n",
    "        k_fold = int(h['k_fold'])\n",
    "        seed = int(h['seed'])\n",
    "        precision = float(h['precision'])\n",
    "        gamma = float(h['gamma'])\n",
    "        \n",
    "        batch_size = 1\n",
    "\n",
    "        avg_mse_tr = 0\n",
    "        avg_mse_te = 0\n",
    "\n",
    "        # split data in k fold\n",
    "        k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "        for k in range(0, k_fold):\n",
    "            \n",
    "            # get split data\n",
    "            x_tr, x_te, y_tr, y_te = cross_data(y, x, k_indices, k)\n",
    "\n",
    "            # form data with polynomial degree:\n",
    "            x_tr = build_poly(x_tr, degree)\n",
    "            x_te = build_poly(x_te, degree)\n",
    "            \n",
    "            w = np.zeros(x_tr.shape[1])\n",
    "            loss = float(\"inf\")\n",
    "            diff = float(\"inf\")\n",
    "\n",
    "            while diff > precision:\n",
    "                for y_batch, tx_batch in batch_iter(y_tr, x_tr, batch_size=batch_size, num_batches=1):\n",
    "                    \n",
    "                    # compute a stochastic gradient and loss\n",
    "                    err = y_batch - tx_batch.dot(w)\n",
    "                    grad = -tx_batch.T.dot(err) / len(err)\n",
    "                    \n",
    "                    # compute lasso\n",
    "                    omega = np.vectorize(lambda wi: -np.sign(wi))(w)          \n",
    "            \n",
    "                    # update w through the stochastic gradient update\n",
    "                    w = w - gamma * (grad + lambda_ * omega)\n",
    "                    \n",
    "                    loss += err * batch_size / y_tr.shape[0] \n",
    "\n",
    "                # calculate loss & update diff\n",
    "                diff = loss\n",
    "                loss = compute_mse(y_tr, x_tr, w)\n",
    "                diff = diff - loss\n",
    "                \n",
    "            # calculate the loss for train and test data + add it:\n",
    "            avg_mse_tr += compute_mse(y_tr, x_tr, w) / k_fold\n",
    "            avg_mse_te += compute_mse(y_te, x_te, w) / k_fold\n",
    "\n",
    "        return {\n",
    "            \"avg_mse_tr\": avg_mse_tr,\n",
    "            \"avg_mse_te\": avg_mse_te\n",
    "        }, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = SGD_Lasso_MSE_FixedDegree_CrossValidation_Model(x, y)\n",
    "\n",
    "hs = { \n",
    "    'degree': np.arange(10), \n",
    "    'lambda': np.logspace(-10, -5, 10),\n",
    "    'k_fold': 5,\n",
    "    'seed': 0,\n",
    "    'precision': 0.001,\n",
    "    'gamma': np.logspace(-10, -5, 5)\n",
    "}\n",
    "\n",
    "res = myModel.evaluate(hs, filename='results/SGD_Lasso_MSE_FixedDegree_CrossValidation_Model')\n",
    "\n",
    "plot_heatmap(res, hs, 'avg_mse_te', 'degree', 'lambda')\n",
    "plot_heatmap(res, hs, 'avg_mse_te', 'degree', 'gamma')\n",
    "plot_heatmap(res, hs, 'avg_mse_te', 'lambda', 'gamma')\n",
    "\n",
    "find_arg_min(res, 'avg_mse_te')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

