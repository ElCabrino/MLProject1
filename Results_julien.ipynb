{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from algebra import *\n",
    "from cache import *\n",
    "from costs import *\n",
    "from features import *\n",
    "from gradients import *\n",
    "from helpers import *\n",
    "from model import *\n",
    "from splits import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_SAMPLE = False\n",
    "CACHE_DIR = \"test/cache/\" if SUB_SAMPLE else \"cache/\"\n",
    "SUBMISSIONS_DIR = \"test/submissions/\" if SUB_SAMPLE else \"submissions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x, ids = load_csv_data('data/train.csv', SUB_SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Analytical Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression with Fixed Degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Without Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_standardize_expand(y, x, h):\n",
    "        \n",
    "    degree = int(h['degree'])\n",
    "\n",
    "    x = remove_errors(x)\n",
    "    x = remove_outliers(x)\n",
    "    x = standardize_all(x)\n",
    "    x = remove_nan_features(x)\n",
    "    x = build_poly(x, degree)\n",
    "\n",
    "    return y, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression_analytical(y, x, h):\n",
    "\n",
    "    lambda_ = float(h['lambda'])\n",
    "    degree = int(h['degree'])\n",
    "\n",
    "    w = ridge_regression(y, x, lambda_)\n",
    "    \n",
    "    return {\n",
    "        'w': w,\n",
    "        'mse': compute_mse(y, x, w)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = { \n",
    "    'degree': [5, 6, 7], \n",
    "    'lambda': 1e-4,\n",
    "}\n",
    "\n",
    "_ = evaluate(\n",
    "    clean = clean_standardize_expand, \n",
    "    fit   = ridge_regression_analytical, \n",
    "    x     = x, \n",
    "    y     = y, \n",
    "    hs    = hs, \n",
    "    cache = CACHE_DIR + 'clean_standardize_expand_ridge_regression_analytical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Cross-Validation\n",
    "\n",
    "Here, we implement the same model with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = { \n",
    "    'degree': np.arange(4, 16), \n",
    "    'lambda': np.logspace(-8, -4, 5),\n",
    "    'k_fold': 4,\n",
    "    'seed': 0\n",
    "}\n",
    "\n",
    "def mse(y, x, w):\n",
    "    return { 'mse' : compute_mse(y, x, w) }\n",
    "\n",
    "fit_function = cross_validate(ridge_regression_analytical, mse)\n",
    "\n",
    "evaluate(\n",
    "    clean = clean_standardize_expand, \n",
    "    fit   = fit_function, \n",
    "    x     = x,\n",
    "    y     = y, \n",
    "    hs    = hs, \n",
    "    cache = CACHE_DIR + 'clean_standardize_expand_cross_validate_ridge_regression_analytical_mse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myModel.predict(best_h, x, y, SUBMISSIONS_DIR + 'RidgeRegression_MSE_FixedDegree_CrossValidation_Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descents\n",
    "\n",
    "#### Least Square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_logistic(clean):\n",
    "    \n",
    "    def inner_function(y, x, h):\n",
    "        y, x = clean(y, x, h)\n",
    "        y = np.where(y == -1, 1, 0)\n",
    "        return y, x\n",
    "    \n",
    "    return inner_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 - err = {'err': 172990.08696124953}\n",
      "iteration 50 - err = {'err': 161964.0305706002}\n",
      "iteration 100 - err = {'err': 155461.3253420889}\n",
      "iteration 150 - err = {'err': 151012.992179333}\n",
      "iteration 200 - err = {'err': 147759.38347746438}\n",
      "iteration 250 - err = {'err': 145274.78911853925}\n",
      "iteration 300 - err = {'err': 143344.85159421063}\n",
      "iteration 350 - err = {'err': 141795.15260002683}\n",
      "iteration 400 - err = {'err': 140532.65878743728}\n",
      "iteration 450 - err = {'err': 139463.93193769513}\n",
      "iteration 500 - err = {'err': 138593.81965106502}\n",
      "iteration 550 - err = {'err': 137843.37670337656}\n",
      "iteration 600 - err = {'err': 137206.79834315073}\n",
      "iteration 650 - err = {'err': 136650.53114688542}\n",
      "iteration 700 - err = {'err': 136182.2422368654}\n",
      "iteration 750 - err = {'err': 135761.27072757765}\n",
      "iteration 800 - err = {'err': 135389.27112363384}\n",
      "iteration 850 - err = {'err': 135065.385452786}\n",
      "iteration 900 - err = {'err': 134771.28328439203}\n",
      "iteration 950 - err = {'err': 134513.37056380778}\n",
      "iteration 1000 - err = {'err': 134276.80520333053}\n",
      "iteration 1050 - err = {'err': 134066.088853403}\n",
      "iteration 1100 - err = {'err': 133868.30463666093}\n",
      "iteration 1150 - err = {'err': 133685.46534061374}\n",
      "iteration 1200 - err = {'err': 133520.22635868163}\n",
      "iteration 1250 - err = {'err': 133363.80976272153}\n",
      "iteration 1300 - err = {'err': 133219.20728646542}\n",
      "iteration 1350 - err = {'err': 133085.45366438344}\n",
      "iteration 1400 - err = {'err': 132958.58787958202}\n",
      "iteration 1450 - err = {'err': 132842.60198928296}\n",
      "iteration 1500 - err = {'err': 132729.7170374837}\n",
      "iteration 1550 - err = {'err': 132626.28724302346}\n",
      "iteration 1600 - err = {'err': 132523.88149080088}\n",
      "iteration 1650 - err = {'err': 132431.07006479267}\n",
      "iteration 1700 - err = {'err': 132340.6845836109}\n",
      "iteration 1750 - err = {'err': 132258.90130288343}\n",
      "iteration 1800 - err = {'err': 132173.76412001508}\n",
      "iteration 1850 - err = {'err': 132093.39036677504}\n",
      "iteration 1900 - err = {'err': 132016.17494953398}\n",
      "iteration 1950 - err = {'err': 131941.73550897508}\n",
      "iteration 2000 - err = {'err': 131869.97461733653}\n",
      "iteration 2050 - err = {'err': 131801.9018397094}\n",
      "iteration 2100 - err = {'err': 131735.51609943263}\n",
      "iteration 2150 - err = {'err': 131672.0105965017}\n",
      "iteration 2200 - err = {'err': 131609.44147093565}\n",
      "iteration 2250 - err = {'err': 131547.3369614284}\n",
      "iteration 2300 - err = {'err': 131490.195738681}\n",
      "iteration 2350 - err = {'err': 131432.86203002176}\n",
      "iteration 2400 - err = {'err': 131377.5589075489}\n",
      "iteration 2450 - err = {'err': 131321.2828788317}\n",
      "iteration 2500 - err = {'err': 131269.27947143122}\n",
      "iteration 2550 - err = {'err': 131216.73139203683}\n",
      "iteration 2600 - err = {'err': 131165.96292114252}\n",
      "iteration 2650 - err = {'err': 131115.58343726926}\n",
      "iteration 2700 - err = {'err': 131066.59133251396}\n",
      "iteration 2750 - err = {'err': 131018.10229734582}\n",
      "iteration 2800 - err = {'err': 130971.65756954021}\n",
      "iteration 2850 - err = {'err': 130927.52233376901}\n",
      "iteration 2900 - err = {'err': 130883.30757964526}\n",
      "iteration 2950 - err = {'err': 130839.77605901047}\n",
      "iteration 0 - err = {'err': 173257.03396427777}\n",
      "iteration 50 - err = {'err': 171793.4700009036}\n",
      "iteration 100 - err = {'err': 170433.78410336562}\n",
      "iteration 150 - err = {'err': 169163.1980058303}\n",
      "iteration 200 - err = {'err': 167966.50307124408}\n",
      "iteration 250 - err = {'err': 166852.36543758708}\n",
      "iteration 300 - err = {'err': 165803.29273081882}\n",
      "iteration 350 - err = {'err': 164811.14588050055}\n",
      "iteration 400 - err = {'err': 163874.6206629856}\n",
      "iteration 450 - err = {'err': 162982.15338128436}\n",
      "iteration 500 - err = {'err': 162136.56574685485}\n",
      "iteration 550 - err = {'err': 161336.50187348522}\n",
      "iteration 600 - err = {'err': 160572.029703873}\n",
      "iteration 650 - err = {'err': 159842.43963850156}\n",
      "iteration 700 - err = {'err': 159152.28694320977}\n",
      "iteration 750 - err = {'err': 158484.90593083214}\n",
      "iteration 800 - err = {'err': 157844.33305842715}\n",
      "iteration 850 - err = {'err': 157233.02071968594}\n",
      "iteration 900 - err = {'err': 156651.1135026617}\n",
      "iteration 950 - err = {'err': 156090.08551204437}\n",
      "iteration 1000 - err = {'err': 155552.8556223979}\n",
      "iteration 1050 - err = {'err': 155036.37567114373}\n",
      "iteration 1100 - err = {'err': 154529.97938363388}\n",
      "iteration 1150 - err = {'err': 154047.68669963966}\n",
      "iteration 1200 - err = {'err': 153579.1894843684}\n"
     ]
    }
   ],
   "source": [
    "def logistic_gradient(y, x, w, h):\n",
    "    \n",
    "    return compute_logistic_gradient(y, x, w)\n",
    "            \n",
    "def logistic_error(y, x, w):\n",
    "    \n",
    "    return { 'err': compute_logistic_error(y, x, w) }\n",
    "\n",
    "hs = {\n",
    "    'batch_size': 2500,\n",
    "    'degree': np.concat([[-2], np.arange(1, 7)]),\n",
    "    'gamma': [1e-2, 1e-3], \n",
    "    'k_fold': 4,\n",
    "    'lambda': 0,\n",
    "    'max_iters': 3000,\n",
    "    'num_batches': 1,\n",
    "    'seed': 1,\n",
    "}\n",
    "\n",
    "\n",
    "stochastic_logistic_descent = stochastic_gradient_descent_e(logistic_gradient, compute_logistic_error, True)\n",
    "_ = evaluate(\n",
    "    clean = map_logistic(clean_standardize_expand), \n",
    "    fit   = stochastic_gradient_descent_e(\n",
    "        logistic_gradient, \n",
    "        logistic_error, \n",
    "        True\n",
    "    ), \n",
    "    y     = y, \n",
    "    x     = x, \n",
    "    hs    = hs, \n",
    "    cache = CACHE_DIR + 'clean_standardize_expand_stochastic_logistic_descent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
