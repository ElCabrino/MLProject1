{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helpers.py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load features.py\n",
    "# This file contains all functions related to transforming and cleaning\n",
    "# the features\n",
    "import numpy as np\n",
    "\n",
    "MIN_MAX_VALUES = {\n",
    "    0:  (0,  500), 1 : (0,  220), 2: (0, 300),  3: (0, 320),\n",
    "    5:  (0, 2300),                              8: (0, 100),  9: (0, 1000),\n",
    "    10: (0,    6),                             13: (0, 150),\n",
    "                   16: (0,  180),                            19: (0,  210),\n",
    "                   21: (0, 1000),              23: (0, 500),\n",
    "                   26: (0,  250),                            29: (0,  500),\n",
    "}\n",
    "\n",
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\"\"\"\n",
    "    # this function should return the matrix formed\n",
    "    # by applying the polynomial basis to the input data\n",
    "    return np.array([np.concatenate([[1.0]] + [[xi ** d for d in range(1, degree+1)] for xi in row]) for row in x])\n",
    "\n",
    "def standardize(x):\n",
    "    \"\"\"Standardize the original data set.\"\"\"\n",
    "    mean_x = np.mean(x)\n",
    "    x = x - mean_x\n",
    "    std_x = np.std(x)\n",
    "    x = x / std_x\n",
    "    return x, mean_x, std_x\n",
    "\n",
    "def standardize_all(x):\n",
    "    x = np.apply_along_axis(lambda xi: standardize(xi)[0], 0, x)\n",
    "    return x\n",
    "\n",
    "def clamp(data, min_value, max_value, mode='clamp'):\n",
    "    if mode == 'clamp':\n",
    "        data[data > max_value] = max_value\n",
    "        data[data < min_value] = min_value\n",
    "    else:\n",
    "        data[data > max_value] = np.NaN\n",
    "        data[data < min_value] = np.NaN\n",
    "\n",
    "def remove_errors(data):\n",
    "    data = data.copy()\n",
    "    data[data == -999.0] = np.NaN\n",
    "    return data\n",
    "\n",
    "def remove_outliers(data, mode='clamp'):\n",
    "    data = data.copy()\n",
    "\n",
    "    for key, value in MIN_MAX_VALUES.items():\n",
    "        clamp(data[:, key], value[0], value[1], mode)\n",
    "\n",
    "    return data\n",
    "\n",
    "def remove_nan_features(x):\n",
    "    x = x[:, ~np.any(np.isnan(x), axis=0)]\n",
    "    return x\n",
    "\n",
    "def remove_nan_samples(x, y):\n",
    "    mask = np.any(np.isnan(x), axis=1)\n",
    "    return x[~mask], y[~mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x, ids = load_csv_data('data/train.csv', sub_sample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data\n",
    "\n",
    "*\"How much data dowe have in total?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- There are 5000 data points in the dataset\n",
      "- There are 30 features in x\n"
     ]
    }
   ],
   "source": [
    "print(\"- There are {} data points in the dataset\".format(x.shape[0]))\n",
    "print(\"- There are {} features in x\".format(x.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_features(x):\n",
    "    mean_x = np.nanmean(x, axis=0)\n",
    "    var_x = np.nanvar(x, axis=0)\n",
    "    max_x = np.nanmax(x, axis=0)\n",
    "    min_x = np.nanmin(x, axis=0)\n",
    "    nan_x = np.sum(np.isnan(x), axis=0)\n",
    "    \n",
    "    print(f'Shape: {x.s}')\n",
    "    print('ID |    Mean    |    Var     |    Min     |    Max     |   #NaN   |')\n",
    "    print('---|------------|------------|------------|------------|----------|')\n",
    "    \n",
    "    for f in range(0, x.shape[1]):\n",
    "        mean = '{0:.3f}'.format(mean_x[f]).rjust(10)\n",
    "        var = '{0:.3f}'.format(var_x[f]).rjust(10)\n",
    "        maxi = '{0:.3f}'.format(max_x[f]).rjust(10)\n",
    "        mini = '{0:.3f}'.format(min_x[f]).rjust(10)\n",
    "        nani = str(nan_x[f]).rjust(8)\n",
    "        identifier = str(f).rjust(2)\n",
    "    \n",
    "        print('{} | {} | {} | {} | {} | {} |'.format(identifier, mean, var, mini, maxi, nani))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\"What does the data look like?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_features(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\"What does the clean data look like?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bddcb026a0cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mx_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdescribe_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "def clean_data(x):\n",
    "    \n",
    "    x = remove_errors(x)\n",
    "    x = remove_outliers(x)\n",
    "    x = standardize_all(x)\n",
    "    x = remove_nan_features(x)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "x_clean = clean_data(x)\n",
    "describe_features(x_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histo_feature(data, i, ax=None, b=None):\n",
    "    \n",
    "    indexes = ~np.isnan(data[:,i])\n",
    "    \n",
    "    if b == None:\n",
    "        color = 'blue'\n",
    "    elif b:\n",
    "        indexes = indexes & (y == 1)\n",
    "        color='green'\n",
    "    else:\n",
    "        indexes = indexes & (y == -1)\n",
    "        color='red'\n",
    "        \n",
    "    if ax ==None:\n",
    "        ax = plt\n",
    "    \n",
    "    ax.hist(data[:,i][indexes], 250, facecolor=color, alpha=0.75)\n",
    "    \n",
    "def histo_features(data, b=None):\n",
    "    fig = plt.figure(figsize = (15,15))\n",
    "    \n",
    "    for i in range(0, 30):\n",
    "        ax = fig.add_subplot(6,5,i+1)\n",
    "        histo_feature(data, i, ax=ax, b=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histo_features(x_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histo_features(x_clean, b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histo_features(x_clean, b=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp(data, max_value):\n",
    "    data[data > max_value] = np.NaN\n",
    "\n",
    "def remove_outliers(data):\n",
    "    data = data.copy()\n",
    "    clamp(data[:, 0], 500)\n",
    "    clamp(data[:, 1], 220)\n",
    "    clamp(data[:, 2], 300)\n",
    "    clamp(data[:, 3], 320)\n",
    "    # 4\n",
    "    clamp(data[:, 5], 2300)\n",
    "    # 6\n",
    "    # 7\n",
    "    clamp(data[:, 8], 100)\n",
    "    clamp(data[:, 9], 1000)\n",
    "    clamp(data[:, 10], 6)\n",
    "    # 11\n",
    "    # 12\n",
    "    clamp(data[:, 13], 150)\n",
    "    # 14\n",
    "    # 15\n",
    "    clamp(data[:, 16], 180)\n",
    "    # 17 \n",
    "    # 18\n",
    "    clamp(data[:, 19], 210)\n",
    "    # 20\n",
    "    clamp(data[:, 21], 1000)\n",
    "    # 22\n",
    "    clamp(data[:, 23], 500)\n",
    "    # 24\n",
    "    # 25\n",
    "    clamp(data[:, 26], 250)\n",
    "    # 27\n",
    "    # 28\n",
    "    clamp(data[:, 29], 500)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_clamped = remove_outliers(x_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histo_features(x_clamped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histo_features(x_clamped, b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histo_features(x_clamped, b=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_features(data):\n",
    "    fig = plt.figure(figsize = (15,150))\n",
    "    \n",
    "    for i in range(0, 60):\n",
    "        ax = fig.add_subplot(30,2,i+1)\n",
    "        histo_feature(data, int(i/2.0), ax=ax, b=(i%2==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_features(x_clamped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    \"\"\"Standardize the original data set.\"\"\"\n",
    "    mean_x = np.mean(x)\n",
    "    x = x - mean_x\n",
    "    std_x = np.std(x)\n",
    "    x = x / std_x\n",
    "    return x, mean_x, std_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_std = np.vectorize(lambda x: standardize(x))(x_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.apply_along_axis(lambda x: standardize(x)[0], 0, x_clean)\n",
    "mask = np.all(np.isnan(x_test), axis=0)\n",
    "x_test = x_test[:, ~mask]\n",
    "\n",
    "# describe_features(x_test.dropna())\n",
    "\n",
    "describe_features(x_test)\n",
    "# d[:,~np.all(np.isnan(d), axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
