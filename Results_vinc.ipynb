{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from algebra import *\n",
    "from cache import *\n",
    "from costs import *\n",
    "from features import *\n",
    "from gradients import *\n",
    "from helpers import *\n",
    "from model import *\n",
    "from splits import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_SAMPLE = True\n",
    "CACHE_DIR = \"test/cache/\" if SUB_SAMPLE else \"cache/\"\n",
    "SUBMISSIONS_DIR = \"test/submissions/\" if SUB_SAMPLE else \"submissions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y, x, ids = load_csv_data('data/train.csv', SUB_SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_standardize_expand(y, x, h):\n",
    "        \n",
    "    degree = int(h['degree'])\n",
    "\n",
    "    x = remove_errors(x)\n",
    "    x = remove_outliers(x)\n",
    "    x = standardize_all(x)\n",
    "    x = remove_nan_features(x)\n",
    "    x = build_poly(x, degree)\n",
    "\n",
    "    return y, x\n",
    "\n",
    "def clean_expand(y, x, h):\n",
    "        \n",
    "    degree = int(h['degree'])\n",
    "\n",
    "    x = remove_errors(x)\n",
    "    x = remove_outliers(x)\n",
    "    x = remove_nan_features(x)\n",
    "    x = build_poly(x, degree)\n",
    "\n",
    "    return y, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_logistic(clean):\n",
    "    \n",
    "    def inner_function(y, x, h):\n",
    "        y, x = clean(y, x, h)\n",
    "        y = np.where(y == 1, 0, 1)\n",
    "        return y, x\n",
    "    \n",
    "    return inner_function\n",
    "\n",
    "def logistic_gradient(y, x, w, h):\n",
    "    \n",
    "    return compute_logistic_gradient(y, x, w)\n",
    "\n",
    "def logistic_gradient_ridge(y, x, w, h):\n",
    "    \n",
    "    lambda_ = h['lambda']\n",
    "    \n",
    "    return compute_logistic_gradient(y, x, w) + lambda_ * w\n",
    "            \n",
    "def logistic_error(y, x, w, h):\n",
    "    \n",
    "    lambda_ = h['lambda']\n",
    "    \n",
    "    logistic_err = compute_logistic_error(y, x, w)\n",
    "    n_err = compute_error_count(predict_logistic)(y, x, w)\n",
    "    \n",
    "    return {\n",
    "        'logistic_err': logistic_err,\n",
    "        'n_err': n_err\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100 - err = {'logistic_err': 7.566294588457086, 'n_err': 0.3286}\n",
      "iteration 200 - err = {'logistic_err': 7.566294588457086, 'n_err': 0.3286}\n",
      "iteration 300 - err = {'logistic_err': 7.566294588457086, 'n_err': 0.3286}\n",
      "iteration 400 - err = {'logistic_err': 15.45955631439477, 'n_err': 0.6714}\n",
      "iteration 500 - err = {'logistic_err': 7.566294588457086, 'n_err': 0.3286}\n",
      "iteration 600 - err = {'logistic_err': 7.566294588457086, 'n_err': 0.3286}\n",
      "iteration 700 - err = {'logistic_err': 15.45955631439477, 'n_err': 0.6714}\n",
      "iteration 800 - err = {'logistic_err': 7.566294588457086, 'n_err': 0.3286}\n",
      "iteration 900 - err = {'logistic_err': 7.566294588457086, 'n_err': 0.3286}\n",
      "iteration 1000 - err = {'logistic_err': 7.566294588457086, 'n_err': 0.3286}\n"
     ]
    }
   ],
   "source": [
    "hs = {\n",
    "    'batch_size': 1,\n",
    "    'degree': 1,#np.concatenate([np.arange(1, 7)]),\n",
    "    'gamma': 1e-1, \n",
    "    'k_fold': 4,\n",
    "    'lambda': 0,\n",
    "    'max_iters': 1000,\n",
    "    'num_batches': 1,\n",
    "    'seed': 1\n",
    "}\n",
    "\n",
    "cache = Cache(CACHE_DIR + 'AAAAAAAABBCCDEF')\n",
    "\n",
    "_ = evaluate(\n",
    "    clean = map_logistic(clean_expand), \n",
    "    fit   = descent_with_cache(\n",
    "        descent    = stochastic_gradient_descent_e(logistic_gradient), \n",
    "        loss       = logistic_error, \n",
    "        round_size = 100,\n",
    "        cache      = cache,\n",
    "        log        = True\n",
    "    ), \n",
    "    y     = y,\n",
    "    x     = x,\n",
    "    hs    = hs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mle(y, x, w):\n",
    "    res = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        xnTW = x[i].T@w\n",
    "        res += np.log(1+np.exp(xnTW))-y[i]*xnTW\n",
    "    return res / y.shape[0]\n",
    "\n",
    "def print_values(y, x, w):\n",
    "    for i in range(y.shape[0]):\n",
    "        print(\"y: \" + str(y[i]))\n",
    "        print(\"pred :  \" + str(x[i].T@w))\n",
    "\n",
    "def compute_mle2(y, x, w):\n",
    "    y_pred = logistic_function(x @ w)\n",
    "    return - (y @ np.log(y_pred) + (1 - y) @ np.log(1 - y_pred))\n",
    "\n",
    "class First_Order_Logistic_Regression_Model2(Model):\n",
    "\n",
    "    def prepare(self, x, y, h):\n",
    "        \n",
    "        degree = int(h['degree'])\n",
    "\n",
    "        x = remove_errors(x)\n",
    "        x = remove_outliers(x)\n",
    "        #x = standardize_all(x)\n",
    "        x = remove_nan_features(x)\n",
    "        x = build_poly(x, degree)\n",
    "        #print('avant')\n",
    "        #print(y[:5])\n",
    "        y = np.where(y == -1, 0, 1)\n",
    "        #print('apr√®s')\n",
    "        #print(y[:5])\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def fit(self, x, y, h={}):\n",
    "        \n",
    "        batch_size = int(h['batch_size'])\n",
    "        n_iters = int(h['n_iters'])\n",
    "        gamma = float(h['gamma'])\n",
    "        \n",
    "        initial_w = np.zeros(x.shape[1])\n",
    "        return logistic_regression(y, x, initial_w, batch_size, n_iters, gamma)\n",
    "    \n",
    "    def test(self, x, y, w, h):\n",
    "        #y = np.where(y == 0, -1, 1)\n",
    "        mse = compute_mle(y, x, w)\n",
    "        #print_values(y, x, w)\n",
    "        if np.isnan(mse):\n",
    "            mse = np.inf\n",
    "        return { 'mse': mse }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "myModel = CrossValidationModel(First_Order_Logistic_Regression_Model2())\n",
    "\n",
    "n_iters = [100]\n",
    "batch_size = [50]\n",
    "\n",
    "degrees = np.arange(1,4)\n",
    "gammas = np.logspace(-20, -10, 5)\n",
    "gammas = gammas[:len(gammas)-1]\n",
    "\n",
    "hs={\n",
    "    'n_iters': n_iters,\n",
    "    'batch_size': batch_size,\n",
    "    'degree': degrees,\n",
    "    'gamma': gammas,\n",
    "    'k_fold': [4],\n",
    "    'seed': [0]\n",
    "}\n",
    "\n",
    "res = myModel.evaluate(x, y, hs, filename=CACHE_DIR+'Logistic_Regression_ExploFullSampleNoStdProp')\n",
    "\n",
    "#print(res)\n",
    "\n",
    "plot_heatmap(res, hs, 'mse_te', 'degree', 'gamma')\n",
    "\n",
    "#res_mse = np.vectorize(lambda x: x['mse'])(res)\n",
    "#x_axis = np.unique(np.vectorize(lambda x: x['gamma'])(res))\n",
    "#y_axis = np.unique(np.vectorize(lambda x: x['degree'])(res))\n",
    "\n",
    "#plot_heatmap(res, hs, 'mse', 'degree', 'gamma')\n",
    "find_arg_min(res, 'mse_te')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = {'batch_size': 1.0,\n",
    " 'degree': 6.0,\n",
    " 'gamma': 10**-20,\n",
    " 'k_fold': 4.0,\n",
    " 'n_iters': 10.0,\n",
    " 'seed': 0.0,\n",
    " 'mse_te': 0.3988701335328735,\n",
    " 'mse_tr': 0.3988200000042866}\n",
    "\n",
    "myModel.predict(hs, x, y, SUBMISSIONS_DIR + 'Logistic_Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Order Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regularized_Logistic_Regression_Model(Model):\n",
    "\n",
    "    def prepare(self, x, y, h):\n",
    "        \n",
    "        degree = int(h['degree'])\n",
    "\n",
    "        x = remove_errors(x)\n",
    "        x = remove_outliers(x)\n",
    "        #x = standardize_all(x)\n",
    "        x = remove_nan_features(x)\n",
    "        x = build_poly(x, degree)\n",
    "        \n",
    "        y = np.where(y == -1, 0, 1)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def fit(self, x, y, h={}):\n",
    "        \n",
    "        batch_size = int(h['batch_size'])\n",
    "        n_iters = int(h['n_iters'])\n",
    "        gamma = float(h['gamma'])\n",
    "        lambda_ = float(h['lambda'])\n",
    "        \n",
    "        initial_w = np.zeros(x.shape[1])\n",
    "        return reg_logistic_regression(y, x, initial_w, batch_size, n_iters, gamma, lambda_)\n",
    "    \n",
    "    def test(self, x, y, w, h):\n",
    "        mse = compute_mle(y, x, w)\n",
    "        if np.isnan(mse):\n",
    "            mse = np.inf\n",
    "        return { 'mse': mse }\n",
    "    \n",
    "    def predict(self, h, x_tr, y_tr, name):\n",
    "\n",
    "        x_tr, y_tr = self.prepare(x_tr, y_tr, h)\n",
    "        w = self.fit(x_tr, y_tr, h)\n",
    "\n",
    "        _, x_pred, ids = load_csv_data(\"data/test.csv\", sub_sample=False)\n",
    "        x_pred, _ = self.prepare(x_pred, None, h)\n",
    "        y_pred = np.dot(data, weights)\n",
    "        #modified for logistic regression\n",
    "        y_pred[np.where(y_pred <= 0.5)] = -1\n",
    "        y_pred[np.where(y_pred > 0.5)] = 1\n",
    "\n",
    "        create_csv_submission(ids, y_pred, name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = CrossValidationModel(Regularized_Logistic_Regression_Model())\n",
    "\n",
    "n_iters = [1000]\n",
    "batch_size = [1]\n",
    "degrees = 4#np.arange(1,8)\n",
    "gammas = 10**-7 #np.logspace(-10, -5, 10)\n",
    "lambdas = 10**-8#np.logspace(-8, -5, 3)\n",
    "\n",
    "hs={\n",
    "    'n_iters': n_iters,\n",
    "    'batch_size': batch_size,\n",
    "    'degree': degrees,\n",
    "    'gamma': gammas,\n",
    "    'lambda': lambdas,\n",
    "    'k_fold': [4],\n",
    "    'seed': [0]\n",
    "}\n",
    "\n",
    "res = myModel.evaluate(x, y, hs, filename=CACHE_DIR+'Regularized_Logistic_Regression_Explo')\n",
    "\n",
    "\n",
    "#plot_heatmap(res, hs, 'mse_te', 'degree', 'gamma')\n",
    "\n",
    "#res_mse = np.vectorize(lambda x: x['mse'])(res)\n",
    "#x_axis = np.unique(np.vectorize(lambda x: x['gamma'])(res))\n",
    "#y_axis = np.unique(np.vectorize(lambda x: x['degree'])(res))\n",
    "\n",
    "plot_heatmap(res, hs, 'mse_te', 'degree', 'lambda')\n",
    "plt.figure(2)\n",
    "plot_heatmap(res, hs, 'mse_te', 'degree', 'gamma')\n",
    "find_arg_min(res, 'mse_te')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = {'batch_size': 1,\n",
    " 'degree': 4,\n",
    " 'gamma': 1e-07,\n",
    " 'k_fold': 4,\n",
    " 'lambda': 1e-08,\n",
    " 'n_iters': 10000,\n",
    " 'seed': 0,\n",
    " 'mse_tr': 0.6896604235218645,\n",
    " 'mse_te': 0.6896430727585345}\n",
    "\n",
    "\n",
    "myModel.predict(hs, x, y, SUBMISSIONS_DIR + 'Regularized_Logistic_RegressionNoStd')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "csv_file = SUBMISSIONS_DIR + 'Regularized_Logistic_RegressionNoStd'\n",
    "\n",
    "data = pandas.read_csv(csv_file)\n",
    "\n",
    "l = data.Prediction\n",
    "\n",
    "counter = 0\n",
    "for i in l:\n",
    "    if i == 1:\n",
    "        counter += 1\n",
    "\n",
    "print(counter/568238)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression_MSE_Degree_Model(Model):\n",
    "\n",
    "    def prepare(self, x, y, h):\n",
    "        \n",
    "        degree = int(h['degree'])\n",
    "\n",
    "        x = remove_errors(x)\n",
    "        x = remove_outliers(x)\n",
    "        x = standardize_all(x)\n",
    "        x = remove_nan_features(x)\n",
    "        x = build_poly(x, degree)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def fit(self, x, y, h={}):\n",
    "\n",
    "        lambda_ = float(h['lambda'])\n",
    "\n",
    "        return ridge_regression(y, x, lambda_)\n",
    "    \n",
    "    def test(self, x, y, w, h):\n",
    "        mse = compute_mse(y, x, w)\n",
    "        if np.isnan(mse):\n",
    "            mse = np.inf\n",
    "        return { 'mse': mse }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = CrossValidationModel(RidgeRegression_MSE_Degree_Model())\n",
    "\n",
    "degrees = np.arange(10, 14)\n",
    "lambdas = np.logspace(-6, -4,10)\n",
    "\n",
    "hs={\n",
    "    'degree': degrees,\n",
    "    'lambda': lambdas,\n",
    "    'k_fold': [4],\n",
    "    'seed': [0]\n",
    "}\n",
    "\n",
    "res = myModel.evaluate(x, y, hs, filename=CACHE_DIR+'Ridge_Explo_Vinc')\n",
    "\n",
    "\n",
    "plot_heatmap(res, hs, 'mse_te', 'degree', 'lambda')\n",
    "find_arg_min(res, 'mse_te')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lasso_SGD_MSE_Degree_Model(Model):\n",
    "\n",
    "    def prepare(self, x, y, h):\n",
    "        \n",
    "        degree = int(h['degree'])\n",
    "\n",
    "        x = remove_errors(x)\n",
    "        x = remove_outliers(x)\n",
    "        x = standardize_all(x)\n",
    "        x = remove_nan_features(x)\n",
    "        x = build_poly(x, degree)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def fit(self, x, y, h={}):\n",
    "        \n",
    "        batch_size = int(h['batch_size'])\n",
    "        n_iters = int(h['n_iters'])\n",
    "        lambda_ = float(h['lambda'])\n",
    "        gamma = float(h['gamma'])\n",
    "\n",
    "        initial_w = np.zeros(x.shape[1])\n",
    "\n",
    "        return lasso_stochastic_gradient_descent(y, x, initial_w, batch_size, n_iters, gamma, lambda_)\n",
    "    \n",
    "    def test(self, x, y, w, h):\n",
    "            mse = compute_mse(y, x, w)\n",
    "            if np.isnan(mse):\n",
    "                mse = np.inf\n",
    "            return { 'mse': mse }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = CrossValidationModel(Lasso_SGD_MSE_Degree_Model())\n",
    "\n",
    "degrees = np.arange(4)\n",
    "lambdas = np.logspace(-3, -1,5)\n",
    "gammas = np.logspace(-15, -10, 3)\n",
    "\n",
    "hs={\n",
    "    'batch_size': 1,\n",
    "    'n_iters': 1000,\n",
    "    'degree': degrees,\n",
    "    'lambda': lambdas,\n",
    "    'gamma': gammas,\n",
    "    'k_fold': [4],\n",
    "    'seed': [0]\n",
    "}\n",
    "\n",
    "res = myModel.evaluate(x, y, hs, filename=CACHE_DIR+'Lasso_Explo_VincTEST')\n",
    "\n",
    "\n",
    "plot_heatmap(res, hs, 'mse_te', 'degree', 'lambda')\n",
    "plot_heatmap(res, hs, 'mse_te', 'degree', 'gamma')\n",
    "find_arg_min(res, 'mse_te')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
