{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run algebra.py\n",
    "%run cache.py\n",
    "%run costs.py\n",
    "%run features.py\n",
    "%run gradients.py\n",
    "%run helpers.py\n",
    "%run model.py\n",
    "%run models.py\n",
    "%run splits.py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_SAMPLE = False\n",
    "CACHE_DIR = \"test/cache/\" if SUB_SAMPLE else \"cache/\"\n",
    "SUBMISSIONS_DIR = \"test/submissions/\" if SUB_SAMPLE else \"submissions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(data_path, sub_sample=True):\n",
    "    \"\"\"Loads data and returns y (class labels), tX (features) and ids (event ids)\"\"\"\n",
    "    y = np.genfromtxt(data_path, delimiter=\",\", skip_header=1, dtype=str, usecols=1)\n",
    "    x = np.genfromtxt(data_path, delimiter=\",\", skip_header=1)\n",
    "    ids = x[:, 0].astype(np.int)\n",
    "    input_data = x[:, 2:]\n",
    "\n",
    "    # convert class labels from strings to binary (-1,1)\n",
    "    yb = np.ones(len(y))\n",
    "    yb[np.where(y=='b')] = -1\n",
    "\n",
    "    # sub-sample\n",
    "    if sub_sample:\n",
    "        yb = yb[::50]\n",
    "        input_data = input_data[::50]\n",
    "        ids = ids[::50]\n",
    "\n",
    "    return yb, input_data, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y, x, ids = load_csv_data('data/train.csv', SUB_SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mle(y, x, w):\n",
    "    res = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        xnTW = x[i].T@w\n",
    "        res += np.log(1+np.exp(xnTW))-y[i]*xnTW\n",
    "    return res / y.shape[0]\n",
    "\n",
    "def print_values(y, x, w):\n",
    "    for i in range(y.shape[0]):\n",
    "        print(\"y: \" + str(y[i]))\n",
    "        print(\"pred :  \" + str(x[i].T@w))\n",
    "\n",
    "def compute_mle2(y, x, w):\n",
    "    y_pred = logistic_function(x @ w)\n",
    "    return - (y @ np.log(y_pred) + (1 - y) @ np.log(1 - y_pred))\n",
    "\n",
    "class First_Order_Logistic_Regression_Model2(Model):\n",
    "\n",
    "    def prepare(self, x, y, h):\n",
    "        \n",
    "        degree = int(h['degree'])\n",
    "\n",
    "        x = remove_errors(x)\n",
    "        x = remove_outliers(x)\n",
    "        #x = standardize_all(x)\n",
    "        x = remove_nan_features(x)\n",
    "        x = build_poly(x, degree)\n",
    "        #print('avant')\n",
    "        #print(y[:5])\n",
    "        y = np.where(y == -1, 0, 1)\n",
    "        #print('apr√®s')\n",
    "        #print(y[:5])\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def fit(self, x, y, h={}):\n",
    "        \n",
    "        batch_size = int(h['batch_size'])\n",
    "        n_iters = int(h['n_iters'])\n",
    "        gamma = float(h['gamma'])\n",
    "        \n",
    "        initial_w = np.zeros(x.shape[1])\n",
    "        return logistic_regression(y, x, initial_w, batch_size, n_iters, gamma)\n",
    "    \n",
    "    def test(self, x, y, w, h):\n",
    "        #y = np.where(y == 0, -1, 1)\n",
    "        mse = compute_mle(y, x, w)\n",
    "        #print_values(y, x, w)\n",
    "        if np.isnan(mse):\n",
    "            mse = np.inf\n",
    "        return { 'mse': mse }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "myModel = CrossValidationModel(First_Order_Logistic_Regression_Model2())\n",
    "\n",
    "n_iters = [100]\n",
    "batch_size = [50]\n",
    "\n",
    "degrees = np.arange(1,4)\n",
    "gammas = np.logspace(-20, -10, 5)\n",
    "gammas = gammas[:len(gammas)-1]\n",
    "\n",
    "hs={\n",
    "    'n_iters': n_iters,\n",
    "    'batch_size': batch_size,\n",
    "    'degree': degrees,\n",
    "    'gamma': gammas,\n",
    "    'k_fold': [4],\n",
    "    'seed': [0]\n",
    "}\n",
    "\n",
    "res = myModel.evaluate(x, y, hs, filename=CACHE_DIR+'Logistic_Regression_ExploFullSampleNoStdProp')\n",
    "\n",
    "#print(res)\n",
    "\n",
    "plot_heatmap(res, hs, 'mse_te', 'degree', 'gamma')\n",
    "\n",
    "#res_mse = np.vectorize(lambda x: x['mse'])(res)\n",
    "#x_axis = np.unique(np.vectorize(lambda x: x['gamma'])(res))\n",
    "#y_axis = np.unique(np.vectorize(lambda x: x['degree'])(res))\n",
    "\n",
    "#plot_heatmap(res, hs, 'mse', 'degree', 'gamma')\n",
    "find_arg_min(res, 'mse_te')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = {'batch_size': 1.0,\n",
    " 'degree': 6.0,\n",
    " 'gamma': 10**-20,\n",
    " 'k_fold': 4.0,\n",
    " 'n_iters': 10.0,\n",
    " 'seed': 0.0,\n",
    " 'mse_te': 0.3988701335328735,\n",
    " 'mse_tr': 0.3988200000042866}\n",
    "\n",
    "myModel.predict(hs, x, y, SUBMISSIONS_DIR + 'Logistic_Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Order Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regularized_Logistic_Regression_Model(Model):\n",
    "\n",
    "    def prepare(self, x, y, h):\n",
    "        \n",
    "        degree = int(h['degree'])\n",
    "\n",
    "        x = remove_errors(x)\n",
    "        x = remove_outliers(x)\n",
    "        #x = standardize_all(x)\n",
    "        x = remove_nan_features(x)\n",
    "        x = build_poly(x, degree)\n",
    "        \n",
    "        y = np.where(y == -1, 0, 1)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def fit(self, x, y, h={}):\n",
    "        \n",
    "        batch_size = int(h['batch_size'])\n",
    "        n_iters = int(h['n_iters'])\n",
    "        gamma = float(h['gamma'])\n",
    "        lambda_ = float(h['lambda'])\n",
    "        \n",
    "        initial_w = np.zeros(x.shape[1])\n",
    "        return reg_logistic_regression(y, x, initial_w, batch_size, n_iters, gamma, lambda_)\n",
    "    \n",
    "    def test(self, x, y, w, h):\n",
    "        mse = compute_mle(y, x, w)\n",
    "        if np.isnan(mse):\n",
    "            mse = np.inf\n",
    "        return { 'mse': mse }\n",
    "    \n",
    "    def predict(self, h, x_tr, y_tr, name):\n",
    "\n",
    "        x_tr, y_tr = self.prepare(x_tr, y_tr, h)\n",
    "        w = self.fit(x_tr, y_tr, h)\n",
    "\n",
    "        _, x_pred, ids = load_csv_data(\"data/test.csv\", sub_sample=False)\n",
    "        x_pred, _ = self.prepare(x_pred, None, h)\n",
    "        y_pred = np.dot(data, weights)\n",
    "        #modified for logistic regression\n",
    "        y_pred[np.where(y_pred <= 0.5)] = -1\n",
    "        y_pred[np.where(y_pred > 0.5)] = 1\n",
    "\n",
    "        create_csv_submission(ids, y_pred, name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = CrossValidationModel(Regularized_Logistic_Regression_Model())\n",
    "\n",
    "n_iters = [1000]\n",
    "batch_size = [1]\n",
    "degrees = 4#np.arange(1,8)\n",
    "gammas = 10**-7 #np.logspace(-10, -5, 10)\n",
    "lambdas = 10**-8#np.logspace(-8, -5, 3)\n",
    "\n",
    "hs={\n",
    "    'n_iters': n_iters,\n",
    "    'batch_size': batch_size,\n",
    "    'degree': degrees,\n",
    "    'gamma': gammas,\n",
    "    'lambda': lambdas,\n",
    "    'k_fold': [4],\n",
    "    'seed': [0]\n",
    "}\n",
    "\n",
    "res = myModel.evaluate(x, y, hs, filename=CACHE_DIR+'Regularized_Logistic_Regression_Explo')\n",
    "\n",
    "\n",
    "#plot_heatmap(res, hs, 'mse_te', 'degree', 'gamma')\n",
    "\n",
    "#res_mse = np.vectorize(lambda x: x['mse'])(res)\n",
    "#x_axis = np.unique(np.vectorize(lambda x: x['gamma'])(res))\n",
    "#y_axis = np.unique(np.vectorize(lambda x: x['degree'])(res))\n",
    "\n",
    "plot_heatmap(res, hs, 'mse_te', 'degree', 'lambda')\n",
    "plt.figure(2)\n",
    "plot_heatmap(res, hs, 'mse_te', 'degree', 'gamma')\n",
    "find_arg_min(res, 'mse_te')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = {'batch_size': 1,\n",
    " 'degree': 4,\n",
    " 'gamma': 1e-07,\n",
    " 'k_fold': 4,\n",
    " 'lambda': 1e-08,\n",
    " 'n_iters': 10000,\n",
    " 'seed': 0,\n",
    " 'mse_tr': 0.6896604235218645,\n",
    " 'mse_te': 0.6896430727585345}\n",
    "\n",
    "\n",
    "myModel.predict(hs, x, y, SUBMISSIONS_DIR + 'Regularized_Logistic_RegressionNoStd')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "csv_file = SUBMISSIONS_DIR + 'Regularized_Logistic_RegressionNoStd'\n",
    "\n",
    "data = pandas.read_csv(csv_file)\n",
    "\n",
    "l = data.Prediction\n",
    "\n",
    "counter = 0\n",
    "for i in l:\n",
    "    if i == 1:\n",
    "        counter += 1\n",
    "\n",
    "print(counter/568238)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression_MSE_Degree_Model(Model):\n",
    "\n",
    "    def prepare(self, x, y, h):\n",
    "        \n",
    "        degree = int(h['degree'])\n",
    "\n",
    "        x = remove_errors(x)\n",
    "        x = remove_outliers(x)\n",
    "        x = standardize_all(x)\n",
    "        x = remove_nan_features(x)\n",
    "        x = build_poly(x, degree)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def fit(self, x, y, h={}):\n",
    "\n",
    "        lambda_ = float(h['lambda'])\n",
    "\n",
    "        return ridge_regression(y, x, lambda_)\n",
    "    \n",
    "    def test(self, x, y, w, h):\n",
    "        mse = compute_mse(y, x, w)\n",
    "        if np.isnan(mse):\n",
    "            mse = np.inf\n",
    "        return { 'mse': mse }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = CrossValidationModel(RidgeRegression_MSE_Degree_Model())\n",
    "\n",
    "degrees = np.arange(10, 14)\n",
    "lambdas = np.logspace(-6, -4,10)\n",
    "\n",
    "hs={\n",
    "    'degree': degrees,\n",
    "    'lambda': lambdas,\n",
    "    'k_fold': [4],\n",
    "    'seed': [0]\n",
    "}\n",
    "\n",
    "res = myModel.evaluate(x, y, hs, filename=CACHE_DIR+'Ridge_Explo_Vinc')\n",
    "\n",
    "\n",
    "plot_heatmap(res, hs, 'mse_te', 'degree', 'lambda')\n",
    "find_arg_min(res, 'mse_te')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lasso_SGD_MSE_Degree_Model(Model):\n",
    "\n",
    "    def prepare(self, x, y, h):\n",
    "        \n",
    "        degree = int(h['degree'])\n",
    "\n",
    "        x = remove_errors(x)\n",
    "        x = remove_outliers(x)\n",
    "        x = standardize_all(x)\n",
    "        x = remove_nan_features(x)\n",
    "        x = build_poly(x, degree)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def fit(self, x, y, h={}):\n",
    "        \n",
    "        batch_size = int(h['batch_size'])\n",
    "        n_iters = int(h['n_iters'])\n",
    "        lambda_ = float(h['lambda'])\n",
    "        gamma = float(h['gamma'])\n",
    "\n",
    "        initial_w = np.zeros(x.shape[1])\n",
    "\n",
    "        return lasso_stochastic_gradient_descent(y, x, initial_w, batch_size, n_iters, gamma, lambda_)\n",
    "    \n",
    "    def test(self, x, y, w, h):\n",
    "            mse = compute_mse(y, x, w)\n",
    "            if np.isnan(mse):\n",
    "                mse = np.inf\n",
    "            return { 'mse': mse }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = CrossValidationModel(Lasso_SGD_MSE_Degree_Model())\n",
    "\n",
    "degrees = np.arange(4)\n",
    "lambdas = np.logspace(-3, -1,5)\n",
    "gammas = np.logspace(-15, -10, 3)\n",
    "\n",
    "hs={\n",
    "    'batch_size': 1,\n",
    "    'n_iters': 1000,\n",
    "    'degree': degrees,\n",
    "    'lambda': lambdas,\n",
    "    'gamma': gammas,\n",
    "    'k_fold': [4],\n",
    "    'seed': [0]\n",
    "}\n",
    "\n",
    "res = myModel.evaluate(x, y, hs, filename=CACHE_DIR+'Lasso_Explo_VincTEST')\n",
    "\n",
    "\n",
    "plot_heatmap(res, hs, 'mse_te', 'degree', 'lambda')\n",
    "plot_heatmap(res, hs, 'mse_te', 'degree', 'gamma')\n",
    "find_arg_min(res, 'mse_te')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
