{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run algebra.py\n",
    "%run cache.py\n",
    "%run costs.py\n",
    "%run features.py\n",
    "%run gradients.py\n",
    "%run helpers.py\n",
    "%run model.py\n",
    "%run models.py\n",
    "%run splits.py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_SAMPLE = False\n",
    "CACHE_DIR = \"test/cache/\" if SUB_SAMPLE else \"cache/\"\n",
    "SUBMISSIONS_DIR = \"test/submissions/\" if SUB_SAMPLE else \"submissions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(data_path, sub_sample=True):\n",
    "    \"\"\"Loads data and returns y (class labels), tX (features) and ids (event ids)\"\"\"\n",
    "    y = np.genfromtxt(data_path, delimiter=\",\", skip_header=1, dtype=str, usecols=1)\n",
    "    x = np.genfromtxt(data_path, delimiter=\",\", skip_header=1)\n",
    "    ids = x[:, 0].astype(np.int)\n",
    "    input_data = x[:, 2:]\n",
    "\n",
    "    # convert class labels from strings to binary (-1,1)\n",
    "    yb = np.ones(len(y))\n",
    "    yb[np.where(y=='b')] = -1\n",
    "\n",
    "    # sub-sample\n",
    "    if sub_sample:\n",
    "        yb = yb[::50]\n",
    "        input_data = input_data[::50]\n",
    "        ids = ids[::50]\n",
    "\n",
    "    return yb, input_data, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y, x, ids = load_csv_data('data/train.csv', SUB_SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class First_Order_Logistic_Regression_Model2(Model):\n",
    "\n",
    "    def prepare(self, x, y, h):\n",
    "        \n",
    "        degree = int(h['degree'])\n",
    "\n",
    "        x = remove_errors(x)\n",
    "        x = remove_outliers(x)\n",
    "        x = standardize_all(x)\n",
    "        x = remove_nan_features(x)\n",
    "        x = build_poly(x, degree)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def fit(self, x, y, h={}):\n",
    "        \n",
    "        batch_size = int(h['batch_size'])\n",
    "        n_iters = int(h['n_iters'])\n",
    "        gamma = float(h['gamma'])\n",
    "        \n",
    "        initial_w = np.zeros(x.shape[1])\n",
    "        return logistic_regression(y, x, initial_w, batch_size, n_iters, gamma)\n",
    "    \n",
    "    def test(self, x, y, w, h):\n",
    "        mse = compute_mse(y, x, w)\n",
    "        if np.isnan(mse):\n",
    "            mse = np.inf\n",
    "        return { 'mse': mse }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([78]),)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch_size': 1.0,\n",
       " 'degree': 6.0,\n",
       " 'gamma': 2.7825594022071258e-11,\n",
       " 'k_fold': 4.0,\n",
       " 'n_iters': 500.0,\n",
       " 'seed': 0.0,\n",
       " 'mse_te': 0.49816723583794337,\n",
       " 'mse_tr': 0.4982079429179726}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myModel = CrossValidationModel(First_Order_Logistic_Regression_Model2())\n",
    "\n",
    "n_iters = [500]\n",
    "batch_size = [1]\n",
    "degrees = np.arange(9)\n",
    "gammas = np.logspace(-15, -10, 10)\n",
    "\n",
    "hs={\n",
    "    'n_iters': n_iters,\n",
    "    'batch_size': batch_size,\n",
    "    'degree': degrees,\n",
    "    'gamma': gammas,\n",
    "    'k_fold': [4],\n",
    "    'seed': [0]\n",
    "}\n",
    "\n",
    "res = myModel.evaluate(x, y, hs, filename=CACHE_DIR+'Logistic_Regression_Explo')\n",
    "\n",
    "#print(res)\n",
    "\n",
    "#plot_heatmap(res, hs, 'mse_te', 'degree', 'gamma')\n",
    "\n",
    "#res_mse = np.vectorize(lambda x: x['mse'])(res)\n",
    "#x_axis = np.unique(np.vectorize(lambda x: x['gamma'])(res))\n",
    "#y_axis = np.unique(np.vectorize(lambda x: x['degree'])(res))\n",
    "\n",
    "#plot_heatmap(res, hs, 'mse', 'degree', 'gamma')\n",
    "find_arg_min(res, 'mse_te')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = {'batch_size': 10.0,\n",
    " 'degree': 1.0,\n",
    " 'gamma': 0.0003548133892335753,\n",
    " 'k_fold': 4.0,\n",
    " 'n_iters': 100000.0,\n",
    " 'seed': 0.0,\n",
    " 'mse_te': 0.3988701335328735,\n",
    " 'mse_tr': 0.3988200000042866}\n",
    "\n",
    "myModel.predict(hs, x, y, SUBMISSIONS_DIR + 'Logistic_Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Order Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regularized_Logistic_Regression_Model(Model):\n",
    "\n",
    "    def prepare(self, x, y, h):\n",
    "        \n",
    "        degree = int(h['degree'])\n",
    "\n",
    "        x = remove_errors(x)\n",
    "        x = remove_outliers(x)\n",
    "        x = standardize_all(x)\n",
    "        x = remove_nan_features(x)\n",
    "        x = build_poly(x, degree)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def fit(self, x, y, h={}):\n",
    "        \n",
    "        batch_size = int(h['batch_size'])\n",
    "        n_iters = int(h['n_iters'])\n",
    "        gamma = float(h['gamma'])\n",
    "        lambda_ = float(h['lambda'])\n",
    "        \n",
    "        initial_w = np.zeros(x.shape[1])\n",
    "        return reg_logistic_regression(y, x, initial_w, batch_size, n_iters, gamma, lambda_)\n",
    "    \n",
    "    def test(self, x, y, w, h):\n",
    "        mse = compute_mse(y, x, w)\n",
    "        if np.isnan(mse):\n",
    "            mse = np.inf\n",
    "        return { 'mse': mse }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e8d90f0e15fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCACHE_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'SecondOrd_Logistic_Regression_Explo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#print(res)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Master/ML/MLProject1/model.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, hs, filename)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhs_pairs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mstarmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         '''\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     def starmap_async(self, func, iterable, chunksize=None, callback=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vincent/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-18:\n",
      "  File \"/Users/vincent/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-17:\n",
      "Process ForkPoolWorker-20:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vincent/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vincent/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/vincent/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/vincent/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/vincent/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/vincent/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/vincent/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/vincent/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/vincent/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/Users/vincent/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/vincent/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/vincent/Dropbox/Master/ML/MLProject1/model.py\", line 32, in evaluate_step\n",
      "    w = self.fit(x, y, h)\n",
      "  File \"/Users/vincent/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/Users/vincent/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/Users/vincent/Dropbox/Master/ML/MLProject1/model.py\", line 125, in fit\n",
      "    w = self.model.fit(x_tr, y_tr, h)\n",
      "  File \"/Users/vincent/Dropbox/Master/ML/MLProject1/model.py\", line 32, in evaluate_step\n",
      "    w = self.fit(x, y, h)\n",
      "  File \"/Users/vincent/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/Users/vincent/Dropbox/Master/ML/MLProject1/model.py\", line 32, in evaluate_step\n",
      "    w = self.fit(x, y, h)\n",
      "  File \"/Users/vincent/Dropbox/Master/ML/MLProject1/model.py\", line 125, in fit\n",
      "    w = self.model.fit(x_tr, y_tr, h)\n",
      "  File \"<ipython-input-11-a9cdf6d153fd>\", line 23, in fit\n",
      "    return reg_logistic_regression(y, x, initial_w, batch_size, n_iters, gamma, lambda_)\n",
      "  File \"<ipython-input-11-a9cdf6d153fd>\", line 23, in fit\n",
      "    return reg_logistic_regression(y, x, initial_w, batch_size, n_iters, gamma, lambda_)\n",
      "  File \"/Users/vincent/Dropbox/Master/ML/MLProject1/model.py\", line 125, in fit\n",
      "    w = self.model.fit(x_tr, y_tr, h)\n",
      "  File \"/Users/vincent/Dropbox/Master/ML/MLProject1/gradients.py\", line 100, in reg_logistic_regression\n",
      "    grad = compute_logistic_gradient(y_batch, tx_batch, w)\n",
      "  File \"/Users/vincent/Dropbox/Master/ML/MLProject1/gradients.py\", line 99, in reg_logistic_regression\n",
      "    for y_batch, tx_batch in batch_iter(y, tx, batch_size=batch_size, num_batches=1):\n",
      "  File \"<ipython-input-11-a9cdf6d153fd>\", line 23, in fit\n",
      "    return reg_logistic_regression(y, x, initial_w, batch_size, n_iters, gamma, lambda_)\n",
      "  File \"/Users/vincent/Dropbox/Master/ML/MLProject1/model.py\", line 32, in evaluate_step\n",
      "    w = self.fit(x, y, h)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/vincent/Dropbox/Master/ML/MLProject1/gradients.py\", line 74, in batch_iter\n",
      "    shuffled_tx = tx[shuffle_indices]\n",
      "  File \"/Users/vincent/Dropbox/Master/ML/MLProject1/gradients.py\", line 99, in reg_logistic_regression\n",
      "    for y_batch, tx_batch in batch_iter(y, tx, batch_size=batch_size, num_batches=1):\n",
      "  File \"/Users/vincent/Dropbox/Master/ML/MLProject1/model.py\", line 125, in fit\n",
      "    w = self.model.fit(x_tr, y_tr, h)\n",
      "  File \"/Users/vincent/Dropbox/Master/ML/MLProject1/gradients.py\", line 74, in batch_iter\n",
      "    shuffled_tx = tx[shuffle_indices]\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-11-a9cdf6d153fd>\", line 23, in fit\n",
      "    return reg_logistic_regression(y, x, initial_w, batch_size, n_iters, gamma, lambda_)\n",
      "  File \"/Users/vincent/Dropbox/Master/ML/MLProject1/gradients.py\", line 99, in reg_logistic_regression\n",
      "    for y_batch, tx_batch in batch_iter(y, tx, batch_size=batch_size, num_batches=1):\n",
      "  File \"/Users/vincent/Dropbox/Master/ML/MLProject1/gradients.py\", line 74, in batch_iter\n",
      "    shuffled_tx = tx[shuffle_indices]\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "myModel = CrossValidationModel(Regularized_Logistic_Regression_Model())\n",
    "\n",
    "n_iters = [1000]\n",
    "batch_size = [1]\n",
    "degrees = np.arange(5,15)\n",
    "gammas = np.logspace(-15, -10, 10)\n",
    "lambdas = np.logspace(-10, 0, 3)\n",
    "\n",
    "hs={\n",
    "    'n_iters': n_iters,\n",
    "    'batch_size': batch_size,\n",
    "    'degree': degrees,\n",
    "    'gamma': gammas,\n",
    "    'lambda': lambdas,\n",
    "    'k_fold': [4],\n",
    "    'seed': [0]\n",
    "}\n",
    "\n",
    "res = myModel.evaluate(x, y, hs, filename=CACHE_DIR+'SecondOrd_Logistic_Regression_Explo')\n",
    "\n",
    "#print(res)\n",
    "\n",
    "#plot_heatmap(res, hs, 'mse_te', 'degree', 'gamma')\n",
    "\n",
    "#res_mse = np.vectorize(lambda x: x['mse'])(res)\n",
    "#x_axis = np.unique(np.vectorize(lambda x: x['gamma'])(res))\n",
    "#y_axis = np.unique(np.vectorize(lambda x: x['degree'])(res))\n",
    "\n",
    "#plot_heatmap(res, hs, 'mse', 'degree', 'gamma')\n",
    "find_arg_min(res, 'mse_te')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
